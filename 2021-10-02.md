# Day 1

## Git
- **init** : git 저장소 초기화
- **status** : 변동사항 확인
- **add** : 파일 스테이징
- **commit** : 커밋하기
- **push** : 원격 저장소에 푸싱
- **pull** : origin에서 변경사항 가져와 합침

## Markdown
---
### 헤더는 #으로 나타내고 6개까지 가능하다
#### ex(H4)
---
### 코드는 ```로 감싼다
```python
print("Hello World!")
```
---
**강조**
*기울임*
---
1. 목록 1
    - 목록 1.1
+ 목록 2
---
표<br>
| 1 | 2 | 3|
|:---|:---:|---:|
|4|5|6|
|7|8||
---
---
## 직장인을 위한 데이터 분석 with 파이썬
pandas 기초와 웹 크롤링 기초를 진행
|        | Selenium + BeautifulSoup | Selenium만 이용|
|:------:|:------------------------:|:---------------:|
|웹 페이지 접속|HTML 정보 다운로드 후 브라우저 영향 없음|웹 페이지 연결 유지 필요|
|웹 페이지 동작|불가능|클릭, 입력 등 조작 가능|
|크롤링 속도|빠름|느림|

selenium과 BeautifulSoup을 이용해서 멜론, 벅스, 지니의 차트를 크롤링하여 엑셀로 변환하는 예제 진행
```python
# melon chart
from selenium import webdriver
from bs4 import BeautifulSoup
import pandas as pd

# melon 접속
driver = webdriver.Chrome('크롬 드라이버 위치')
url = 'https://www.melon.com/chart/index.htm'
driver.get(url)

# html 파일 가져와서 파싱
html = driver.page_source
soup = BeautifulSoup(html, 'html.parser')

song_data = []
rank = 1
songs = soup.select('table > tbody > tr') # 차트 내 곡들 정보 저장
for song in songs: # song_data에 ['melon', 순위, 제목, 가수]를 저장
    title = song.select('div.rank01 > span > a')[0].text
    singer = song.select('div.rank02 > a')[0].text
    song_data.append(['Melon', rank, title, singer])
    rank = rank + 1

# song_data를 데이터프레임으로 제작
columns = ['서비스', '순위', '타이틀', '가수']
pd_data = pd.DataFrame(song_data, columns = columns)

# 데이터프레임을 엑셀로 저장
pd_data.to_excel('./files/melon.xlsx', index=False)
```
해당 예제 활용하여 bugs와 genie도 수집
```python
# 수집한 엑셀 파일 이름들 리스트로 선언
excel_names = ['./files/melon.xlsx', './files/bugs.xlsx', './files/genie.xlsx']

# 수집한 melon, bugs, genie 데이터를 하나의 데이터프레임으로 통합
appended_data = pd.DataFrame()
for name in excel_names:
    pd_data = pd.read_excel(name)
    appended_data = appended_data.append(pd_data)

# 엑셀 파일로 저장
appended_data.to_excel('./files/total.xlsx', index=False)
```